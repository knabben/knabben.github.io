<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>Service Mesh | AK</title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="generator" content="Hugo 0.70.0" />
    
    
      <META NAME="ROBOTS" CONTENT="NOINDEX, NOFOLLOW">
    

    
    
      <link href="/dist/css/app.1cb140d8ba31d5b2f1114537dd04802a.css" rel="stylesheet">
    

    
      <link rel="stylesheet" href="/css/custom.css">
    

    
      
    

    
    
    <meta property="og:title" content="Service Mesh" />
<meta property="og:description" content="Introducing Kubernetes   November 2015, I started to use containers in production, and found some crazy problems involved with this in the process, it went from service discovery to persistent storage in a few days. The environment I used were basically a CoreOS cluster with some peculiarities, like starting services remote with fleet (like kubectl). The setup were composed of a etcd/fleet cluster with 3 machines and units being deployed with an external FLEETCTL_TUNNEL variable." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://knabben.github.io/posts/sm/" />
<meta property="article:published_time" content="2018-10-06T00:00:00+00:00" />
<meta property="article:modified_time" content="2018-10-06T00:00:00+00:00" />
<meta itemprop="name" content="Service Mesh">
<meta itemprop="description" content="Introducing Kubernetes   November 2015, I started to use containers in production, and found some crazy problems involved with this in the process, it went from service discovery to persistent storage in a few days. The environment I used were basically a CoreOS cluster with some peculiarities, like starting services remote with fleet (like kubectl). The setup were composed of a etcd/fleet cluster with 3 machines and units being deployed with an external FLEETCTL_TUNNEL variable.">
<meta itemprop="datePublished" content="2018-10-06T00:00:00&#43;00:00" />
<meta itemprop="dateModified" content="2018-10-06T00:00:00&#43;00:00" />
<meta itemprop="wordCount" content="2103">



<meta itemprop="keywords" content="" /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Service Mesh"/>
<meta name="twitter:description" content="Introducing Kubernetes   November 2015, I started to use containers in production, and found some crazy problems involved with this in the process, it went from service discovery to persistent storage in a few days. The environment I used were basically a CoreOS cluster with some peculiarities, like starting services remote with fleet (like kubectl). The setup were composed of a etcd/fleet cluster with 3 machines and units being deployed with an external FLEETCTL_TUNNEL variable."/>

  </head>

  <body class="ma0 avenir bg-near-white">

    
   
  

  <header>
    <div class="bg-black">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l justify-between items-center center">
    <a href="http://knabben.github.io/" class="f3 fw2 hover-white no-underline white-90 dib">
      AK
    </a>
    <div class="flex-l items-center">
      

      
      














    </div>
  </div>
</nav>

    </div>
  </header>



    <main class="pb7" role="main">
      
  
  <article class="flex-l flex-wrap justify-between mw8 center ph3">
    <header class="mt4 w-100">
      <aside class="instapaper_ignoref b helvetica tracked">
          
        POSTS
      </aside>
      




  <div id="sharing" class="mt3">

    
    <a href="https://www.facebook.com/sharer.php?u=http://knabben.github.io/posts/sm/" class="facebook no-underline" aria-label="share on Facebook">
      <svg height="32px"  style="enable-background:new 0 0 67 67;" version="1.1" viewBox="0 0 67 67" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M28.765,50.32h6.744V33.998h4.499l0.596-5.624h-5.095  l0.007-2.816c0-1.466,0.14-2.253,2.244-2.253h2.812V17.68h-4.5c-5.405,0-7.307,2.729-7.307,7.317v3.377h-3.369v5.625h3.369V50.32z   M33,64C16.432,64,3,50.569,3,34S16.432,4,33,4s30,13.431,30,30S49.568,64,33,64z" style="fill-rule:evenodd;clip-rule:evenodd;"/></svg>

    </a>

    
    
    <a href="https://twitter.com/share?url=http://knabben.github.io/posts/sm/&amp;text=Service%20Mesh" class="twitter no-underline" aria-label="share on Twitter">
      <svg height="32px"  style="enable-background:new 0 0 67 67;" version="1.1" viewBox="0 0 67 67" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M37.167,22.283c-2.619,0.953-4.274,3.411-4.086,6.101  l0.063,1.038l-1.048-0.127c-3.813-0.487-7.145-2.139-9.974-4.915l-1.383-1.377l-0.356,1.017c-0.754,2.267-0.272,4.661,1.299,6.271  c0.838,0.89,0.649,1.017-0.796,0.487c-0.503-0.169-0.943-0.296-0.985-0.233c-0.146,0.149,0.356,2.076,0.754,2.839  c0.545,1.06,1.655,2.097,2.871,2.712l1.027,0.487l-1.215,0.021c-1.173,0-1.215,0.021-1.089,0.467  c0.419,1.377,2.074,2.839,3.918,3.475l1.299,0.444l-1.131,0.678c-1.676,0.976-3.646,1.526-5.616,1.568  C19.775,43.256,19,43.341,19,43.405c0,0.211,2.557,1.397,4.044,1.864c4.463,1.377,9.765,0.783,13.746-1.568  c2.829-1.673,5.657-5,6.978-8.221c0.713-1.716,1.425-4.851,1.425-6.354c0-0.975,0.063-1.102,1.236-2.267  c0.692-0.678,1.341-1.419,1.467-1.631c0.21-0.403,0.188-0.403-0.88-0.043c-1.781,0.636-2.033,0.551-1.152-0.402  c0.649-0.678,1.425-1.907,1.425-2.267c0-0.063-0.314,0.042-0.671,0.233c-0.377,0.212-1.215,0.53-1.844,0.72l-1.131,0.361l-1.027-0.7  c-0.566-0.381-1.361-0.805-1.781-0.932C39.766,21.902,38.131,21.944,37.167,22.283z M33,64C16.432,64,3,50.569,3,34S16.432,4,33,4  s30,13.431,30,30S49.568,64,33,64z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/></svg>

    </a>

    
    <a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=http://knabben.github.io/posts/sm/&amp;title=Service%20Mesh" class="linkedin no-underline" aria-label="share on LinkedIn">
      <svg  height="32px"  style="enable-background:new 0 0 65 65;" version="1.1" viewBox="0 0 65 65" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
  <path d="M50.837,48.137V36.425c0-6.275-3.35-9.195-7.816-9.195  c-3.604,0-5.219,1.983-6.119,3.374V27.71h-6.79c0.09,1.917,0,20.427,0,20.427h6.79V36.729c0-0.609,0.044-1.219,0.224-1.655  c0.49-1.22,1.607-2.483,3.482-2.483c2.458,0,3.44,1.873,3.44,4.618v10.929H50.837z M22.959,24.922c2.367,0,3.842-1.57,3.842-3.531  c-0.044-2.003-1.475-3.528-3.797-3.528s-3.841,1.524-3.841,3.528c0,1.961,1.474,3.531,3.753,3.531H22.959z M34,64  C17.432,64,4,50.568,4,34C4,17.431,17.432,4,34,4s30,13.431,30,30C64,50.568,50.568,64,34,64z M26.354,48.137V27.71h-6.789v20.427  H26.354z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>

    </a>
  </div>

      <h1 class="f1 athelas mt3 mb1">Service Mesh</h1>
      
      
      <time class="f6 mv4 dib tracked" datetime="2018-10-06T00:00:00Z">October 6, 2018</time>

      
      
    </header>
    <div class="nested-copy-line-height lh-copy serif f4 nested-links nested-img mid-gray pr4-l w-two-thirds-l">
<h3 id="headline-1">
Introducing Kubernetes
</h3>
<p>
November 2015, I started to use containers in production, and found some crazy problems involved with this in the process, it went from service discovery to persistent storage in a few days. The environment I used were basically a CoreOS cluster with some peculiarities, like starting services remote with fleet (like kubectl). The setup were composed of a etcd/fleet cluster with 3 machines and units being deployed with an external FLEETCTL_TUNNEL variable.
</p>
<p>
Trying to create an orchestration system by hand looked like a mad task as you can read on the last posts, at least it was a lot of fun, some of the problems I faced with the setup are:
</p>
<ol>
<li>
<p>
Downtime - My container ran on a single machine, when I stopped the unit and started again via fleetctl I had the bootstrap time and the new docker pull couting as a downtime of the service.
</p>
</li>
<li>
<p>
Volume persistence - This is a real pain, the volume mounted on a machine stays on there if the docker is killed, I had to do some X-fleet units hack to keep the container always on that machine.
</p>
</li>
<li>
<p>
Shared configurations - it were solved with etcd
</p>
</li>
<li>
<p>
Service discovery - A consul + registration + workarounds
</p>
</li>
<li>
<p>
Monitoring - A painful (cadvisor + prometheus + alertmanager) setup
</p>
</li>
</ol>
<p>
But as stated on [1], &#34;With the realization that large, expensive, proprietary supercomputers are being replaced by a clusters of commodity boxes running Linux (commoditization), at a fraction of the cost, it is not too much of a stretch to see apllication of this type of technology widespread in the engineering and traditional IT world. The availability of commodity clusters make it possible for small research organizations, It deps, and engineering groups to have their own supercomupters at a fraction of the cost previously required for the equivalten computing capability.&#34;
</p>
<p>
The last definition of a cluster from the same book is: &#34;A closely coupled collection of computer systems that shares a common infrastructure and provides a parallel set of resources to services or applications.&#34;
</p>
<p>
For the problems above (at least) and at the same time a software that fits well on the description is <strong>Kubernetes</strong>.  I could say a container orchestration abstraction layer for the masses. We are not using Maui Cluster Scheduler, ganglia or Nagios anymore, but the core concepts still remains the same.
</p>
<h3 id="headline-2">
Getting started
</h3>
<p>
You can start in a few ways, if you want a single machine to play around try minikube or vagrant, if you have some resources you can use kube-aws to setup an AWS cluster with CoreOS or go with get.k8s.io. The brave ones can test the hack/local-up-cluster.sh and RTFM +1 for this option.
</p>
<h3 id="headline-3">
Problems
</h3>
<h4 id="headline-4">
Monitoring
</h4>
<p>
Here is where Prometheus [2] shines. Sysdig [3] is other technology that is integrating very well with kubernetes nowadays, it can be used for deep pod inspection from the replica set to end process syscall, pretty cool.
</p>
<p>
Want to see how to deploy the Prometheus stack go to the CoreOS blog [3]. Well, this is really content for another post.
</p>
<h4 id="headline-5">
Service Discovery
</h4>
<p>
Kubernetes uses kube-dns, a SkyDNS based solution to create automatic registers of the existent services, so you can reach other pods on differents namespaces like - my-svc.my-namespace.svc.cluster.local, with kube-aws each pod uses it as a default nameserver.
</p>
<h4 id="headline-6">
Shared configuration
</h4>
<p>
Kubernetes have two kinds of sharing data, with the old setup we passed variables to systemd units and had to encrypt the .service files with Blackbox for example before commiting to git, now we have ConfigMaps, key/values pairs of configuration data, think of .ini files shared between the pods on the cluster. We can use secrets and import both on pods specification like
</p>
<p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml">- <span style="color:#66d9ef">name</span>: USE_CRON
  <span style="color:#66d9ef">valueFrom</span>:
    <span style="color:#66d9ef">configMapKeyRef</span>:
      <span style="color:#66d9ef">name</span>: cron-data
      <span style="color:#66d9ef">key</span>: use_cron</code></pre></div>
</p>
<h4 id="headline-7">
Volume persistence
</h4>
<p>
On AWS when you create a POD as part of the specification one can use, the volume goes to other machine if the pod is reeschuleded:
</p>
<p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml">  <span style="color:#66d9ef">containers</span>:
  - <span style="color:#66d9ef">image</span>: nginx
    <span style="color:#66d9ef">name</span>: nginx
    <span style="color:#66d9ef">volumeMounts</span>:
    - <span style="color:#66d9ef">mountPath</span>: /var/log/nginx
      <span style="color:#66d9ef">name</span>: nginx-log
  <span style="color:#66d9ef">volumes</span>:
  - <span style="color:#66d9ef">name</span>: nginx-log
    <span style="color:#66d9ef">awsElasticBlockStore</span>:
      <span style="color:#66d9ef">volumeID</span>: vol<span style="color:#ae81ff">-333333</span>
      <span style="color:#66d9ef">fsType</span>: ext4</code></pre></div>
</p>
<h4 id="headline-8">
Downtime deployments
</h4>
<p>
It uses the idea of deployments for replicasets and pods, in a descriptive form you just say the final state you want your pods to have. You can edit an existing template, or simple set a new container image like:
</p>
<p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl set image deployment/nginx-deployment nginx<span style="color:#f92672">=</span>nginx:1.9.1
deployment <span style="color:#e6db74">&#34;nginx-deployment&#34;</span> image updated</code></pre></div>
</p>
<p>
From deployments documentation [5]:
</p>
<p>
You will see that it first created a new Pod, then deleted some old Pods and created new ones. It does not kill old Pods until a sufficient number of new Pods have come up, and does not create new Pods until a sufficient number of old Pods have been killed
</p>
<h3 id="headline-9">
Service mesh
</h3>
<p>
Microservices cluster management complexity grows easily while your app evolve, questions like how to track the request between services, how to apply A/B tests, how to add metrics for services without changing any code on your application are common when deploying containers on an orchestrator. L4/L7 proxies try to solve these problems in an elegant way.
</p>
<h4 id="headline-10">
Pre - requisites for this tutorial
</h4>
<p>
On the assumption that all systems bellow are installed and working A.K.A you are able to access a running Kubernetes cluster with Istio:
</p>
<h6 id="headline-11">
[1] Kubernetes
</h6>
<h6 id="headline-12">
[2] Istio
</h6>
<h6 id="headline-13">
[3] GRPC gateway
</h6>
<p>
I really recommend doing the workshops and exercises above but if you don&#39;t have the motivation to run the stack step by step, try [4], Google Cloud Platform offers 300 USD of credits with an automatic Istio deployment interface.
</p>
<h3 id="headline-14">
The GRPC gateway
</h3>
<p>
For this example we will deploy 2 different services, the first POD offers a simple GRPC server, the second POD offers a REST API gateway for the GRPC server.
</p>
<h3 id="headline-15">
Istio
</h3>
<p>
From the oficial documentation: Istio provides an easy way to create a network of deployed services with load balancing, service-to-service authentication, monitoring, and more, without requiring any changes in service code. <strong>You add Istio support to services by deploying a special sidecar proxy throughout your environment that intercepts all network communication between microservices, configured and managed using Istioâ€™s control plane functionality.</strong>
</p>
<p>
Long story short: This special sidecar proxy is injected on each pod, basically it&#39;s a modified and dynamic configured envoy (data plane), the other part of this mesh stack is the control plane composed by:
</p>
<h6 id="headline-16">
Pilot - provides service discovery for the Envoy sidecars, traffic management capabilities for intelligent routing.
</h6>
<h6 id="headline-17">
Mixer - a platform-independent component responsible for enforcing access control and usage policies across the service mesh and collecting telemetry data from the Envoy proxy and other services.
</h6>
<h6 id="headline-18">
Istio-Auth - provides strong service-to-service and end-user authentication using mutual TLS, with built-in identity and credential management.
</h6>
<p>
The official documentation is full of good resources and information, our goal here is to be more pragmatic and have some overview and details of Istio capabilities.
</p>
<h3 id="headline-19">
Istio components
</h3>
<p>
After installing Istio you can see the following PODS on istio-system ns. 
</p>
<p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell"> 
kubectl get pods --namespace istio-system
NAME                                 READY     STATUS    RESTARTS   AGE
grafana-2369932619-9nsjq             1/1       Running   <span style="color:#ae81ff">0</span>          17h
istio-ca-191975193-tk62c             1/1       Running   <span style="color:#ae81ff">0</span>          17h
istio-ingress-596799894-40g4p        1/1       Running   <span style="color:#ae81ff">0</span>          17h
istio-initializer-2169589188-35lfx   1/1       Running   <span style="color:#ae81ff">0</span>          17h
istio-mixer-3168313471-0svbr         3/3       Running   <span style="color:#ae81ff">0</span>          17h
istio-pilot-2277488234-j270h         2/2       Running   <span style="color:#ae81ff">0</span>          17h
prometheus-168775884-t7zhd           1/1       Running   <span style="color:#ae81ff">0</span>          17h
servicegraph-2857261069-6d2vg        1/1       Running   <span style="color:#ae81ff">0</span>          17h
zipkin-3660596538-92wv9              1/1       Running   <span style="color:#ae81ff">0</span>          17h</code></pre></div>
</p>
<p>
First, lets take a look on istio-initializer [5], running this POD enable us to automaticaly do the sidecar injection with this disable we need manually recreate the YAML files with istioctl kube-inject command, lets try to see the logs of this pod:
</p>
<p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell"> 
kubectl logs istio-initializer-2169589188-35lfx -n istio-system

http.go:100<span style="color:#f92672">]</span> Starting HTTP service at :8083                                                                       
initializer.go:229<span style="color:#f92672">]</span> Starting Istio sidecar initializer...
initializer.go:230<span style="color:#f92672">]</span> Initializer name set to: sidecar.initializer.istio.io
initializer.go:233<span style="color:#f92672">]</span> Supported kinds:
initializer.go:238<span style="color:#f92672">]</span>     /v1 ReplicationController
initializer.go:238<span style="color:#f92672">]</span>     extensions/v1beta1 Deployment
initializer.go:238<span style="color:#f92672">]</span>     extensions/v1beta1 DaemonSet
initializer.go:238<span style="color:#f92672">]</span>     extensions/v1beta1 ReplicaSet
initializer.go:238<span style="color:#f92672">]</span>     batch/v1 Job
initializer.go:238<span style="color:#f92672">]</span>     batch/v2alpha1 CronJob
initializer.go:238<span style="color:#f92672">]</span>     apps/v1beta1 StatefulSet

<span style="color:#75715e"># After running</span>
helm install --name grpc ./chart

initializer.go:174<span style="color:#f92672">]</span> ObjectMeta initializer info extensions/v1beta1, Kind<span style="color:#f92672">=</span>Deployment default/http-serve policy:<span style="color:#e6db74">&#34;&#34;</span> status:<span style="color:#e6db74">&#34;&#34;</span> &amp;Initializers<span style="color:#f92672">{</span>Pending:<span style="color:#f92672">[{</span>sidecar.initializer.istio.io<span style="color:#f92672">}]</span>,Result:nil,<span style="color:#f92672">}</span>
inject.go:302<span style="color:#f92672">]</span> Sidecar injection policy <span style="color:#66d9ef">for</span> default/http-serve: namespacePolicy:enabled useDefault:true inject:false status:<span style="color:#e6db74">&#34;&#34;</span> required:true
initializer.go:174<span style="color:#f92672">]</span> ObjectMeta initializer info extensions/v1beta1, Kind<span style="color:#f92672">=</span>ReplicaSet default/http-serve-1172935448 policy:<span style="color:#e6db74">&#34;&#34;</span> status:<span style="color:#e6db74">&#34;injected-version-0.3.0&#34;</span> nil
initializer.go:174<span style="color:#f92672">]</span> ObjectMeta initializer info extensions/v1beta1, Kind<span style="color:#f92672">=</span>Deployment default/grpc-internal policy:<span style="color:#e6db74">&#34;&#34;</span> status:<span style="color:#e6db74">&#34;&#34;</span> &amp;Initializers<span style="color:#f92672">{</span>Pending:<span style="color:#f92672">[{</span>sidecar.initializer.istio.io<span style="color:#f92672">}]</span>,Result:nil,<span style="color:#f92672">}</span>
inject.go:302<span style="color:#f92672">]</span> Sidecar injection policy <span style="color:#66d9ef">for</span> default/grpc-internal: namespacePolicy:enabled useDefault:true inject:false status:<span style="color:#e6db74">&#34;&#34;</span> required:true
initializer.go:174<span style="color:#f92672">]</span> ObjectMeta initializer info extensions/v1beta1, Kind<span style="color:#f92672">=</span>ReplicaSet default/grpc-internal-2913712020 policy:<span style="color:#e6db74">&#34;&#34;</span> status:<span style="color:#e6db74">&#34;injected-version-0.3.0&#34;</span> nil</code></pre></div>
</p>
<p>
If you describe the pod you can see the istio-proxy sidecar attached to the main container.
</p>
<p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell"> 
grpc:
...
istio-proxy:
    Image:         docker.io/istio/proxy_debug:0.3.0
    ...
    Args:
      proxy
      sidecar
      -v
      <span style="color:#ae81ff">2</span>
      --configPath
      /etc/istio/proxy
      --serviceCluster
      http-serve
      --discoveryAddress
      istio-pilot.istio-system:15003
      --zipkinAddress
      zipkin.istio-system:9411
      --statsdUdpAddress
      istio-mixer.istio-system:9125
      ...
    State:          Running
    ...</code></pre></div>
</p>
<h4 id="headline-20">
The automatic initializer
</h4>
<p>
This is a very interesting use of Kubernetes Initializer, here occurs the injection of the proxy sidecar before starting the pod.
</p>
<ol>
<li>
<p>
kubernetes adds sidecar.initializer.istio.io to the list of pending initializers in the workload.
</p>
</li>
</ol>
<p>
This is achieved by the following InitializerConfiguration, that comes with Istio setup:
</p>
<p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="color:#66d9ef">apiVersion</span>: admissionregistration.k8s.io/v1alpha1
<span style="color:#66d9ef">kind</span>: InitializerConfiguration
<span style="color:#66d9ef">metadata</span>:
  <span style="color:#66d9ef">name</span>: istio-sidecar
<span style="color:#66d9ef">initializers</span>:
  - <span style="color:#66d9ef">name</span>: sidecar.initializer.istio.io
    <span style="color:#66d9ef">rules</span>:
      - <span style="color:#66d9ef">apiGroups</span>:
          - <span style="color:#e6db74">&#34;*&#34;</span>
        <span style="color:#66d9ef">apiVersions</span>:
          - <span style="color:#e6db74">&#34;*&#34;</span>
        <span style="color:#66d9ef">resources</span>:
          - deployments
          - statefulsets
          - jobs
          - daemonsets
---</code></pre></div>
</p>
<ol>
<li>
<p>
istio-initializer controller observes a new uninitialized workload was created. It finds its configured name sidecar.initializer.istio.io as the first in the list of pending initializers.
</p>
</li>
</ol>
<p>
The [NewInitializer](<a href="https://github.com/istio/istio/blob/master/pilot/platform/kube/inject/initializer.go#L94)">https://github.com/istio/istio/blob/master/pilot/platform/kube/inject/initializer.go#L94)</a> function uses the [ListWatch](<a href="https://github.com/kubernetes/client-go/blob/master/tools/cache/listwatch.go#L52)">https://github.com/kubernetes/client-go/blob/master/tools/cache/listwatch.go#L52)</a> struct, to monitor the new resources created:
</p>
<p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-golang" data-lang="golang"><span style="color:#75715e">// ListWatch knows how to list and watch a set of apiserver resources.  It satisfies the ListerWatcher interface.
</span><span style="color:#75715e">// It is a convenience function for users of NewReflector, etc.
</span><span style="color:#75715e">// ListFunc and WatchFunc must not be nil
</span><span style="color:#75715e"></span><span style="color:#66d9ef">type</span> <span style="color:#a6e22e">ListWatch</span> <span style="color:#66d9ef">struct</span> {
	<span style="color:#a6e22e">ListFunc</span>  <span style="color:#a6e22e">ListFunc</span>
	<span style="color:#a6e22e">WatchFunc</span> <span style="color:#a6e22e">WatchFunc</span>
	<span style="color:#75715e">// DisableChunking requests no chunking for this list watcher.
</span><span style="color:#75715e"></span>	<span style="color:#a6e22e">DisableChunking</span> <span style="color:#66d9ef">bool</span>
}

<span style="color:#75715e">// Snippet of watcher including the Uninitialized assets.
</span><span style="color:#75715e"></span><span style="color:#a6e22e">WatchFunc</span>: <span style="color:#66d9ef">func</span>(<span style="color:#a6e22e">options</span> <span style="color:#a6e22e">metav1</span>.<span style="color:#a6e22e">ListOptions</span>) (<span style="color:#a6e22e">watch</span>.<span style="color:#a6e22e">Interface</span>, <span style="color:#66d9ef">error</span>) {
    <span style="color:#a6e22e">options</span>.<span style="color:#a6e22e">IncludeUninitialized</span> = <span style="color:#66d9ef">true</span>
    <span style="color:#a6e22e">options</span>.<span style="color:#a6e22e">Watch</span> = <span style="color:#66d9ef">true</span>
    <span style="color:#a6e22e">options</span>.<span style="color:#a6e22e">FieldSelector</span> = <span style="color:#a6e22e">fields</span>.<span style="color:#a6e22e">Everything</span>().<span style="color:#a6e22e">String</span>()
    <span style="color:#66d9ef">return</span> <span style="color:#a6e22e">kindClient</span>.<span style="color:#a6e22e">Get</span>().
        <span style="color:#a6e22e">Namespace</span>(<span style="color:#a6e22e">v1</span>.<span style="color:#a6e22e">NamespaceAll</span>).
        <span style="color:#a6e22e">Resource</span>(<span style="color:#a6e22e">kind</span>.<span style="color:#a6e22e">resource</span>).
        <span style="color:#a6e22e">VersionedParams</span>(<span style="color:#f92672">&amp;</span><span style="color:#a6e22e">options</span>, <span style="color:#a6e22e">metav1</span>.<span style="color:#a6e22e">ParameterCodec</span>).
        <span style="color:#a6e22e">Watch</span>()
},</code></pre></div>
</p>
<ol>
<li>
<p>
istio-initializer checks to see if it was responsible for initializing workloads in the namespace of the workload. No further work is done and the initializer ignores the workload if the initializer is not configured for the namespace. By default the initializer is responsible for all namespaces (see configuration options).
</p>
</li>
</ol>
<p>
The function [injectRequired](<a href="https://github.com/istio/istio/blob/master/pilot/platform/kube/inject/inject.go#L232)">https://github.com/istio/istio/blob/master/pilot/platform/kube/inject/inject.go#L232)</a> above is responsible to check the namespace.
</p>
<ol>
<li>
<p>
istio-initializer removes itself from the list of pending initializers. Kubernetes will not finish creating workloads if the list of pending initializers is non-empty. A misconfigured initializer means a broken cluster.
</p>
</li>
</ol>
<p>
The function [initialize](<a href="https://github.com/istio/istio/blob/master/pilot/platform/kube/inject/initializer.go#L202)">https://github.com/istio/istio/blob/master/pilot/platform/kube/inject/initializer.go#L202)</a> (handler from watch) is responsible to remove itself from pending initializer.
</p>
<p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-go" data-lang="go"><span style="color:#75715e">// Remove self from the list of pending Initializers while
</span><span style="color:#75715e">// preserving ordering.
</span><span style="color:#75715e"></span><span style="color:#66d9ef">if</span> <span style="color:#a6e22e">pending</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">obj</span>.<span style="color:#a6e22e">GetInitializers</span>().<span style="color:#a6e22e">Pending</span>; len(<span style="color:#a6e22e">pending</span>) <span style="color:#f92672">==</span> <span style="color:#ae81ff">1</span> {
    <span style="color:#a6e22e">obj</span>.<span style="color:#a6e22e">SetInitializers</span>(<span style="color:#66d9ef">nil</span>)
} <span style="color:#66d9ef">else</span> {
    <span style="color:#a6e22e">obj</span>.<span style="color:#a6e22e">GetInitializers</span>().<span style="color:#a6e22e">Pending</span> = append(<span style="color:#a6e22e">pending</span>[:<span style="color:#ae81ff">0</span>], <span style="color:#a6e22e">pending</span>[<span style="color:#ae81ff">1</span>:]<span style="color:#f92672">...</span>)
}</code></pre></div>
</p>
<ol>
<li>
<p>
istio-initializer checks the default injection policy for the mesh and any possible per-workload overrides to determine whether the sidecar should be injected.
</p>
</li>
</ol>
<p>
The function [injectRequired](<a href="https://github.com/istio/istio/blob/master/pilot/platform/kube/inject/inject.go#L270)">https://github.com/istio/istio/blob/master/pilot/platform/kube/inject/inject.go#L270)</a> defines the default injection policy
</p>
<ol>
<li>
<p>
istio-initializer injects the sidecar template into the workload and submits it back to kubernetes via PATCH.
</p>
</li>
</ol>
<p>
The patcher is passed to the [event handler function](<a href="https://github.com/istio/istio/blob/master/pilot/platform/kube/inject/initializer.go#L224):">https://github.com/istio/istio/blob/master/pilot/platform/kube/inject/initializer.go#L224):</a>
</p>
<p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-go" data-lang="go"><span style="color:#66d9ef">return</span> <span style="color:#a6e22e">patcher</span>(<span style="color:#a6e22e">obj</span>.<span style="color:#a6e22e">GetNamespace</span>(), <span style="color:#a6e22e">obj</span>.<span style="color:#a6e22e">GetName</span>(), <span style="color:#a6e22e">patchBytes</span>, <span style="color:#a6e22e">rObj</span>)</code></pre></div>
</p>
<ol>
<li>
<p>
kubernetes finishes creating the workload as normal and the workload includes the injected sidecar.
</p>
</li>
</ol>
<h4 id="headline-21">
Service access and Ingress
</h4>
<p>
You can access the service with port-forward yet:
</p>
<p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell"> 
kubectl port-forward http-serve-1172935448-zw527 8080:8080

<span style="color:#75715e"># Accessing http://localhost:8080/v1/health</span>

HTTP/1.1 <span style="color:#ae81ff">200</span> OK
&lt; Date: Mon, <span style="color:#ae81ff">01</span> Jan <span style="color:#ae81ff">2018</span> 12:53:02 GMT
&lt; Content-Length: <span style="color:#ae81ff">3</span>
&lt; Content-Type: text/plain; charset<span style="color:#f92672">=</span>utf-8
&lt;
OK</code></pre></div>
</p>
<p>
For external access you can use the Istio Ingress Controller (with the kubernetes.io/ingress.class: istio annotation). The ingress looks like:
</p>
<p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell"> 
Name:             simple-ingress
Namespace:        default
Address:          35.202.0.31
Default backend:  default-http-backend:80 <span style="color:#f92672">(</span>10.56.0.4:8080<span style="color:#f92672">)</span>
Rules:
  Host  Path  Backends
  ----  ----  --------
  *
        /v1/.*   http-serve:8080 <span style="color:#f92672">(</span>&lt;none&gt;<span style="color:#f92672">)</span>
                 grpc-internal:9090 <span style="color:#f92672">(</span>&lt;none&gt;<span style="color:#f92672">)</span>
                 
<span style="color:#75715e"># Access the server via your cluster external IP, note the envoy added headers:</span>

&lt; HTTP/1.1 <span style="color:#ae81ff">200</span> OK
&lt; date: Mon, <span style="color:#ae81ff">01</span> Jan <span style="color:#ae81ff">2018</span> 12:52:39 GMT
&lt; content-length: <span style="color:#ae81ff">3</span>
&lt; content-type: text/plain; charset<span style="color:#f92672">=</span>utf-8
&lt; x-envoy-upstream-service-time: <span style="color:#ae81ff">2</span>
&lt; server: envoy
&lt;
OK</code></pre></div>
</p>
<h4 id="headline-22">
Metrics
</h4>
<p>
Start the loop curl request and checkout the servicegraph, based on prometheus data.
</p>
<p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell"><span style="color:#66d9ef">while</span> true; <span style="color:#66d9ef">do</span> curl -d <span style="color:#e6db74">&#39;{&#34;value&#34;:  &#34;myvalue&#34; }&#39;</span> http://<span style="color:#e6db74">${</span>INGRESS_ADDRESS<span style="color:#e6db74">}</span>/v1/damage; <span style="color:#66d9ef">done</span></code></pre></div>
</p>
<p>
<img src="istio-1.png" alt="istio-1.png" title="istio-1.png" />
</p>
<p>
This is a good example of your services flow, after you can track your request via opentracing and Zipkin:
</p>
<p>
<img src="istio-2.png" alt="istio-2.png" title="istio-2.png" />
</p>
<p>
Or you can check out both services usage on Grafana, the metrics are grabbed automatically.
</p>
<p>
<img src="istio-5.png" alt="istio-5.png" title="istio-5.png" />
<img src="istio-3.png" alt="istio-3.png" title="istio-3.png" />
</p>
<h4 id="headline-23">
Custom HTTP metric
</h4>
<p>
This new metric will increment a counter each time the endpoint is called with analytic=true. To enable the counter run the following command inside the project repo, and call the endpoint with the parameter.
</p>
<p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell"> 
make set-metric
$ curl ... http://<span style="color:#e6db74">${</span>INGRESS_ADDRESS<span style="color:#e6db74">}</span>/v1/damage?analytic<span style="color:#f92672">=</span>true</code></pre></div>
</p>
<p>
The rule will be applied after the match filter and the prometheus adapter being used.
</p>
<p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="color:#66d9ef">apiVersion</span>: <span style="color:#e6db74">&#34;config.istio.io/v1alpha2&#34;</span>
<span style="color:#66d9ef">kind</span>: rule
<span style="color:#66d9ef">metadata</span>:
  <span style="color:#66d9ef">name</span>: analyticprom
  <span style="color:#66d9ef">namespace</span>: istio-system
<span style="color:#66d9ef">spec</span>:
  <span style="color:#66d9ef">match</span>: match(request.path, <span style="color:#e6db74">&#34;/v1/damage?analytic=*&#34;</span>)
  <span style="color:#66d9ef">actions</span>:
  - <span style="color:#66d9ef">handler</span>: promhandler.prometheus
    <span style="color:#66d9ef">instances</span>:
    - analyticcounter.metric</code></pre></div>
</p>
<p>
You can create new Grafana visualizations in the dashboard from Prometheus metrics.
</p>
<p>
<img src="istio-4.png" alt="istio-4.png" title="istio-4.png" />
</p>
<h4 id="headline-24">
Playing around with Mixer adapter
</h4>
<p>
 For those curious about the mixer usage here goes a plugin to send metrics to Librato.
</p>
<p>
 <a href="https://github.com/knabben/librato-adapter">https://github.com/knabben/librato-adapter</a>
</p>
<h4 id="headline-25">
Bibliography
</h4>
<h6 id="headline-26">
[1] <a href="https://github.com/kelseyhightower/kubernetes-the-hard-way">https://github.com/kelseyhightower/kubernetes-the-hard-way</a>
</h6>
<h6 id="headline-27">
[2] <a href="http://blog.christianposta.com/istio-workshop/slides/#/title">http://blog.christianposta.com/istio-workshop/slides/#/title</a>
</h6>
<h6 id="headline-28">
[3] <a href="https://github.com/knabben/grpc-ex">https://github.com/knabben/grpc-ex</a>
</h6>
<h6 id="headline-29">
[4] <a href="https://istio.io/docs/setup/kubernetes/quick-start-gke-dm.html">https://istio.io/docs/setup/kubernetes/quick-start-gke-dm.html</a>
</h6>
<h6 id="headline-30">
[5] <a href="https://istio.io/docs/setup/kubernetes/sidecar-injection.html#automatic-sidecar-injection">https://istio.io/docs/setup/kubernetes/sidecar-injection.html#automatic-sidecar-injection</a>
</h6>
<ul class="pa0">
  
</ul>
<div class="mt6 instapaper_ignoref">
      
      
      </div>
    </div>

    <aside class="w-30-l mt6-l">




</aside>

  </article>

    </main>
    <script type="text/javascript" async
        src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
 MathJax.Hub.Config({
   tex2jax: {
     inlineMath: [['$','$'], ['\\(','\\)']],
     displayMath: [['$$','$$']],
     processEscapes: true,
     processEnvironments: true,
     skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
     TeX: { equationNumbers: { autoNumber: "AMS" },
            extensions: ["AMSmath.js", "AMSsymbols.js"] }
   }
 });
 MathJax.Hub.Queue(function() {
   
   
   
   var all = MathJax.Hub.getAllJax(), i;
   for(i = 0; i < all.length; i += 1) {
     all[i].SourceElement().parentNode.className += ' has-jax';
   }
 });

 MathJax.Hub.Config({
   
   TeX: { equationNumbers: { autoNumber: "AMS" } }
 });
</script>


<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-46699622-2', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>


<footer class="bg-near-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href="http://knabben.github.io/" >
    &copy; 2020 AK
  </a>
    <div>













</div>
  </div>
</footer>

    

  <script src="/dist/js/app.3fc0f988d21662902933.js"></script>


  </body>
</html>
